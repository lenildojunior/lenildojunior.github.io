= Projetos - Processamento Digital de Imagens
José Lenildo Fernandes Dantas Júnior <lenildo.ze@gmail.com>
:toc: left
:toc-title: Sumário
:stem: latexmath

== Projetos da Primeira Unidade

:sectnums:

== Manipulação de Pixels

:sectnums:

=== Negativo de uma região

Este exercício tem como finalidade manipular uma determinada imagem de forma que, após receber duas coordeandas (x,y) que representam, respectivamente, o ponto inicial e final da área desejada, forme um retângulo onde será aplicado o negativo da imagem.


.Área criada com os pontos
image::/image/Retangulo.png[]


O conceito e negativo de uma imagem está atrelado ao fato de acessar os pixels da imagem e subtrair dele o valor máximo que ele pode assunmir. No caso deste exercício, estaremos utilizando uma imagem em tons de cinza com armazenamento de 1 byte, ou seja, cada pixel pode assumir valores entre 0 e 255. Com isso o negativo da imagem pode ser definido como

[source,cpp]
----
image.at<uchar>(i,j)=255-image.at<uchar>(i,j);
----

onde:

* *_image_* : Refere-se a imagem manipulada
* *_.at<uchar>_* : Método para acesso aos pixels de um _unsigned char_ (<uchar>) com 1 _byte_ de tamanho
* *_(i,j)_* : Representam as coordenadas (x,y) do pixel 

Para aplicar este efeito em toda a imagem, basta acrescentá-la a um laço _for()_ como mostra o trecho do código

[source,cpp]
----
for(int i=p1x;i<p2x;i++){
    for(int j=p1y;j<p2y;j++){
      image.at<uchar>(i,j)=255-image.at<uchar>(i,j);
    }
  }
----

O resultado da execução do programa link:/source_codes/regions.cpp[regions.cpp] pode ser visto abaixo

.Imagem utilizada na execução do programa
image::/image/biel.png[]

.Pontos informados pelo usuário
image::/image/execucaoRegions.png[]

.Imagem gerada na saída
image::/image/bielnegativo.png[]


=== Troca de Regiões

Este exercício tem como finalidade colocar em prática o conceito inicial de *_regiões_de_interesse(roi)_*, tornando possível criar um programa capaz de realizar a troca dos quadrantes de uma imagem. Neste exemplo, serão criadas 4 regiões de interesse de forma que, ao final do programa possa ser realizada a troca de cada região pela sua diagonal.

.Divisão das regiões da imagem
image::/image/regioesnomeadas.png[]

Inicialmente, realiza-se a leitura de uma imagem a ser processada pelo programa em duas variáveis do tipo *_Mat_* distintas, de forma que na primeira serão definidas as regiões de interesse que serão copiadas para a segunda.

[source,cpp]
----
 image= imread("biel.png",CV_LOAD_IMAGE_GRAYSCALE);
 newImage= imread("biel.png",CV_LOAD_IMAGE_GRAYSCALE);
----

_Obs: Como a variável *newImage* é igual a *image* também é possível criar uma cópia com a função *clone()*, pois o importante é obtermos uma matriz de dimensões equivalentes a da imagem original para a cópia das regiões_

As regiões de interesse foram definidas utilizando um construtor específico da https://docs.opencv.org/3.1.0/d3/d63/classcv_1_1Mat.html[Classe Mat]

[source,cpp]
----
 Mat (const Mat &m, const Rect &roi)
----

que possui como parâmetros, respectivamente, um objeto da classe _Mat_ e um objeto da classe _Rect_, sendo este último o responsável por informar a região de interesse da imagem _m_.

O primeiro passo é criar quatro objetos da classe _Rect_, referentes as quatro regiões de interesse da imagem, passando como parâmetros as duas coordenadas _x_ e _y_ que delimitarão a área desejada.

.Criação da área desejada para a Região de interesse
[source,cpp]
----
 Rect regA(0,0,image.cols/2,image.rows/2);
 Rect regB(image.cols/2,0,image.cols,image.rows/2);
 Rect regC(0,image.rows/2,image.cols/2,image.rows);
 Rect regD(image.cols/2,image.rows/2,image.cols,image.rows);
----

O segundo passo instintivo seria criar os objetos da classe _Mat_ correspondentes as _roi_. Entretanto ao se executar tal processo a seguinte mensagem de erro será exibida

.Erro exibido pelo console
image::/image/erroMat.png[]

referindo-se que a área de interesse está fora dos limites da imagem.

Para resolver este problema, deve-se executar os seguintes comandos

.Ajuste de dimensionalidade
[source,cpp]
----
	regA = regA & Rect(0,0,image.cols,image.rows);
	regB = regB & Rect(0,0,image.cols,image.rows);
	regC = regC & Rect(0,0,image.cols,image.rows);
	regD = regD & Rect(0,0,image.cols,image.rows);
----

que fará com que os retângulos criados sejam ajustados para atender as dimensões da imagem a qual deseja-se extrair as _roi_.

Após realizar os ajustes, procede-se a criação das regiões de interesse em definitivo, utilizando o contrutor da classe _Mat_ como mostra trecho de codigo 

.Criação das Regiões de Interesse
[source,cpp]
----
  Mat roiA(image,regA);
	Mat roiB(image,regB);
	Mat roiC(image,regC);
	Mat roiD(image,regD);
----

O próximo passo é realizar a troca entre os quadrantes da imagem. Para isso, utiliza-se novamente objetos da classe _Rect_ para definir a localização das _roi_ na imagem de destino.
_Obs:Este passo é opcional, considerando que o objeto pode ser passado diretamente no construtor da classe _Mat_, tratando-se apenas de uma melhor organização.

.Definição das regiões de destino
[source,cpp]
----
  Rect whereRecA(image.cols/2,image.rows/2,image.cols,image.rows); // <1>
	Rect whereRecB(0,image.rows/2,image.cols/2,image.rows);
	Rect whereRecC(image.cols/2,0,image.cols,image.rows/2);
	Rect whereRecD(0,0,image.cols/2,image.rows/2);

	whereRecA = whereRecA & Rect(0,0,image.cols,image.rows); // <2>
	whereRecB = whereRecB & Rect(0,0,image.cols,image.rows);
	whereRecC = whereRecC & Rect(0,0,image.cols,image.rows);
	whereRecD = whereRecD & Rect(0,0,image.cols,image.rows);
----
<1> Definição da região de destino
<2> Ajuste de dimensionalidade

.Esquema de localização das regiões após a troca
image::/image/regioestrocadas.png[]

Com auxílio da função _copyTo()_, copia-se o conteúdo das quatro _roi_ para a imagem de destino nas posições especificadas

.Realizando a troca das diagonais
[source,cpp]
----
	roiA.copyTo(newImage(whereRecA));
	roiB.copyTo(newImage(whereRecB));
	roiC.copyTo(newImage(whereRecC));
	roiD.copyTo(newImage(whereRecD));
----

Com a execução do programa link:/source_codes/trocaregioes.cpp[trocaregioes.cpp] temos a seguinte saída

.Imagem utilizada na execução do programa
image::/image/biel.png[]

.Image gerada após a execução do programa
image::/image/saidaRegioes.png[]

== Contando objetos de uma imagem

O objetivo deste exercício é identificar, em uma imagem passada como entrada, a quantidade de objetos nela presentes. Para tal, desenvolveu-se um algoritmo de rotulação que utilizará o algoritmo _floodfill(ou seedfill)_. Neste código, trabalharemos com imagens binárias em escala de cinza, isto é, imagens que possuam apenas dois valores possíveis: 0 ou 255, onde o valor _"0"_ representa a ausência de cor e 255 representa a cor do objeto.

A rotulação é um processo onde, para cada conglomerado de pixels,com características em comum, encontrado na imagem analisada, será atribuído um valor em comum.

O processo de execução do algoritmo _floodfill_ tem como premissa um dado ponto inicial(semente) e que, a partir dele, sairá percorrendo os 4-vizinhos ou 8-zisinhos deste pixel, procurando por outros que possuam característica semelhante a da semente. A definição do modo de busca de vizinhança é definido no início do algoritmo e a imagem abaixo ilustra os métodos de busca

.Métodos de busca do _floodfill_
image::/image/vizinhos.png[]

A semente é criada como um objeto da classe *_CvPoint_* 

[source,cpp]
----
CvPoint p;
----

que possui duas dimensões, representando as coordenadas x e y da semente. Como deseja-se percorrer toda a imagem, definimos as coordenadas como (0,0) e definimos variáveis para guardar as dimenões da matriz.

.Definindo a coordenada inicial da semente
[source,cpp]
----
  p.x=0;
  p.y=0;
----

[source,cpp]
----
  width=image.size().width;
  height=image.size().height;
----

A imagem abaixo será utilizada para execução do programa, de forma que com ela temos alguns desafios, além de apenas contar os objetos.

.Imagem a ser analizada
image::/image/bolhas.png[]

O algoritmo deve ser capaz, além de contar a quantidade de objetos, determinar quantos deles possuem buracos e quantos não os possuem. Isso nos leva a ter um cuidado com os objetos que tocam as bordas da imagem, pois não se sabe se estes possuem ou não buracos em sua totalidade.Sendo assim, o algoritmo deve excluí-las do processo antes de começar a procurar por objetos.

.Remoção dos objetos nas bordas superior e inferior
[source,cpp]
----
  nobjectsborder=0; // <1>
	for (int i=0;i<height;i=i+height-1){ // <2>
		for(int j=0;j<width;j++){ //<3>
			if (image.at<uchar>(i,j) == 255){ // <4>
				nobjectsborder++;
				p.x=j;
				p.y=i;
				floodFill(image,p,0); // <5>
			}
		}	
	}
----
<1> Contador de objetos presentes nas bordas
<2> Laço de duas iterações para varrer a borda superior e inferior
<3> Laço para varrer horizontalmente as colunas da matriz _image_
<4> Verificação do valor do pixel
<5> Chamada da função _floodfill_ 

.Remoção dos objetos nas bordas laterais
[source,cpp]
----
	for (int i=0;i<height;i++){
		for(int j=0;j<width;j=j + width -1){
			if (image.at<uchar>(i,j) == 255){
				nobjectsborder++;
				p.x=j;
				p.y=i;
				floodFill(image,p,0);
			}
		}	
	}
----

A função _floodfill_ recebe como parâmetros,respectivamente, a matriz de pixels da imagem de entrada(_image_), a semente(_p_) e o valor a ser atribuído aos píxels com características comuns ao procurado. No caso deste exemplo, atribui-se o valor _"0"_ para que sejam preenchidos com a cor do fundo da imagem.

O resultado desta funcionalidade pode ser observado com a execução do arquivo link:/source_codes/removeObjBorda.cpp[removeObjBorda.cpp]

.Imagem de entrada após a remoção dos objetos das bordas
image::/image/labeling.png[]

Agora podemos voltar a lidar com o problema principal de identificar a quantidade de objetos com e sem buracos. Mas como descobrir se um objeto tem ou não buraco se o algoritmo _floodfill_ procura por pixels de características semelhantes e um buraco é a ausência da cor enquanto o objeto é o valor máximo que o pixel pode assumir?
Para que isso seja possível, deve-se alterar a cor do fundo da imagem, utilizando o algoritmo _floodfill_,pois assim ele irá "pintar" apenas a região externa aos objetos e com isso, apenas o interior de objetos com bolhas possuirão valor "0" em seus pixels. Essa tarefa pode ser executada com o trecho de código abaixo.

[source,cpp]
----
	p.x=0;
	p.y=0;
	floodFill(image,p,175); // <1>
---- 
<1> Atribuindo o valor "175" como nova cor de fundo

O resultado pode ser observado com a execução do arquivo link:/source_codes/trocafundo.cpp[trocafundo.cpp]

.Imagem de entrada após alterar o fundo
image::/image/trocafundo.png[]

Com isso, basta executar o algoritmo novamente buscando por pixels com valor "0" e contá-los para termos ciência da quantidade dos que possuem buracos.

.Buscando pelos buracos dos objetos
[source,cpp]
----
nobjectsholes=0;
  for(int i=0; i<height; i++){
    for(int j=0; j<width; j++){
      if(image.at<uchar>(i,j) == 0){
		// achou um objeto
				nobjectsholes++;
				p.x=j;
				p.y=i;
				floodFill(image,p,100);
	  	}
		}
  }	
----

Agora é trivial descobrir a quantidade de objetos sem buraco, basta realizar uma busca por pixels com valor "255", isso contará inclusive os que possuem buracos, e em seguida fazer uma subtração entre os valores dos contadores.

.Contando todos os objetos
[source,cpp]
----
  nobjects=0;
  for(int i=0; i<height; i++){
    for(int j=0; j<width; j++){
      if(image.at<uchar>(i,j) == 255){
		// achou um objeto
				nobjects++;
				p.x=j;
				p.y=i;
				floodFill(image,p,nobjects); // <1>
	  	}
		}
  }

	std::cout<<"com buracos="<<nobjectsholes<<"\nSem buracos="<<(nobjects - nobjectsholes)<<"\n";
  imshow("image", image);
----
<1> Aplicando o processo de rotulação, de forma que cada objeto terá um rótulo

A execução do algoritmo link:/source_codes/labeling2.cpp[labeling2.cpp] tem como resultado de saída

.Saída do programa labeling2.cpp
image::/image/labeling2saida.png[]


== Manipulação de Histogramas

O histograma é uma ferramenta estatística na qual, basicamente, realiza a contagem de cada amostra presente em uma dada população. No contexto de Processamento Digital de Imagens, o histograma conta a ocorrência de cada uma das variações dos valores presentes em cada pixel da imagem desejada.

Considerando uma imagem em tons de cinza, em que cada pixel é armazenado em uma variável do tipo _unsigned char_ de _8 bits_, onde cada pixel pode possuir valores entre 0 e 255, o histograma desta imagem pode ser visto como mostra a imagem abaixo.

.Exemplo de Histograma de uma imagem
image::/image/exemplo_hist.png[]

=== Equalização

O processo de equalização depende da obtenção do histograma da imagem, pois tal processo funciona da seguinte maneira: Dado o histograma de uma imagem, normaliza-se o valor obtido para cada um do valor dos pixels de forma a contemplar toda a faixa a qual os pixels poderiam possuir.
Por exemplo, caso o histograma de uma imagem seja como a a imagem abaixo

.Exemplo de histograma
image::/image/imghist.png[]

Temos que o valor 45 aparece 10 vezes, 70 aparece 15 vezes, 80 aparece 8 vezes e 95 aparece 5 vezes. No total a imagem possui 38 pixels. O processo de normalização ocorre da seguinte forma

[stem]
++++
\frac{10}{38}255 = 67\\   
\frac{25}{38}255 = 167 \\ 
\frac{33}{38}255 = 221\\ 
\frac{38}{38}255 = 255\\ 
++++

onde, agora, temos os novos valores equalizados dos pixels da imagem original que podem ser representados pelo novo histograma

.Histograma da imagem após a equalização
image::/image/imghistequalized.png[]

==== Programa _equalize.cpp_

No OpenCV dispomos da função _calcHist()_ para a obtenção do histograma de uma dada imagem.

.Função _calcHist()_
[source,cpp]
----
    void calcHist(const Mat* images, int nimages, const int* channels, InputArray mask, OutputArray hist, int dims, const int* histSize, const float** ranges, bool uniform=true, bool accumulate=false )
----

Esta função tem como parâmetros, respectivamente:

* Uma referência para a imagem que se deseja processar;
* A quantidade de imagens a serem calculadas;
* Um ponteiro para o array de canais da imagem (0 quando for apenas um canal);
* Uma máscara da região de onde deseja-se calcular o histograma (para a imagem inteira, indica-se uma matriz vazia);
* A variável que irá armazenar o histograma;
* O tamanho da dimensão do histograma;
* O endereço da quantidade de barras do histograma;
* Variáveis que informam o comportamento do histograma (uniformidade, cumulativo)

Ao trabalharmos com imagens coloridas, ou seja, que possuem matrizes representando cada uma das componentes RGB é comum realizar o cálculo do histograma de cada componente de forma separada por ser mais simples, uma vez que, para processar toda a imagem de uma vez seria necessário trabalhar com uma matriz de 256x256x256 elementos. Para realizar a separaçao de cada uma dos componentes utilizamos a função _split()_.

[source,cpp]
----
split (image, planes);
----

Deve-se criar ainda uma variável para cada histograma

[source,cpp]
----
 Mat histImgR(histh, histw, CV_8UC3, Scalar(0,0,0));
  Mat histImgG(histh, histw, CV_8UC3, Scalar(0,0,0));
  Mat histImgB(histh, histw, CV_8UC3, Scalar(0,0,0));
----

Em seguida prosseguir com o cálculo de cada histograma e normaliza-lo de acordo com o tamanho da imagem onde ele será alocado

[source,cpp]
----
calcHist(&planes[0], 1, 0, Mat(), histR, 1,
             &nbins, &histrange,
             uniform, acummulate);
    calcHist(&planes[1], 1, 0, Mat(), histG, 1,
             &nbins, &histrange,
             uniform, acummulate);
    calcHist(&planes[2], 1, 0, Mat(), histB, 1,
             &nbins, &histrange,
             uniform, acummulate);

    normalize(histR, histR, 0, histImgR.rows, NORM_MINMAX, -1, Mat());
    normalize(histG, histG, 0, histImgG.rows, NORM_MINMAX, -1, Mat());
    normalize(histB, histB, 0, histImgB.rows, NORM_MINMAX, -1, Mat());

    histImgR.setTo(Scalar(0));
    histImgG.setTo(Scalar(0));
    histImgB.setTo(Scalar(0));
----

A imagem abaixo representa a saída do programa link:/source_codes/histogram.cpp[histogram.cpp]

.Saída do programa _histogram.cpp_
image::/image/exemphist.png[]

No algoritmo link:/source_codes/equalize.cpp[equalize.cpp] admite-se que a imagem seja dada em tons de cinza, para isso, após a leitura ler a imagem, mesmo que esta seja colorida utilizamos da função _cvtColor()_ como mostra o trecho abaixo, para converter de RGB para _Grayscale_

[source,cpp]
----
cvtColor(image,image, CV_BGR2GRAY);
----

O processo de equalização é realizado com o auxílio da função _equalizeHist()_

[source,cpp]
----
equalizeHist( image,image);
----

A saída do programa link:/source_codes/equalize.cpp[equalize.cpp] pode ser vista nas imagens abaixo.

.Saída do programa _equalize.cpp_
image::/image/saidaequalize.png[]

.Saída do programa _equalize.cpp_ com maior iluminação
image::/image/saidaequalizeluz1.png[]


=== Detecção de movimentos

Para desenvolver o algoritmo que permita perceber se houve algum tipo de movimento, será usado como base o código da seção anterior.
A estratégia utilizada para detectar movimentos será realizar a comparação entre os histogramas de cada frame capturado, comparando o anterior ao seu seguinte até encontrar uma diferença. Esse monitoramento será realizado de forma contínua e o programa mostrará na tela o momento em que o movimento foi detectado, onde serão exibidas duas janelas representando cada um dos frames.

Antes de realizar o processo em si é necessário resolver um problema comum em algumas webcams integradas em notebooks que, ao serem iniciadas com o comando _cap.open(0)_ , inciam com uma imagem bem escura e vaõ ajustando o brilho com o passar do tempo. Esse ajuste é necessário, pois se realizarmos a comparaçã ode histogramas a partir do momento em que a câmera é aberta, o próximo frame, com mais brilho, já terá uma diferença em seu histograma.

Para evitar este problema adotou-se uma estratégia simples: criar um contador que, após o dispositivo de vídeo ser aberto, realizar 40 execuçoes do algoritmo, ou seja, realizar o cálculo do histograma dos 40 primeiros frames sem realizar qualquer tipo de comparação e, a partir do frame 41, onde a câmera já está com seu brilho devidamente ajustado, habilitar a região do código que executa a comparação entre frames.

.Região do código responsável pela comparação de histogramas
[source,cpp]
----
cont++;
if(cont>36)cout<<"MOVE!!!!\n";
if(cont>=40){
	if(histR_old.empty()==true){
		histR_old = histR.clone();
		image_old=image.clone();
	}
	else{
		double histCorrelation = compareHist( histR, histR_old, CV_COMP_CHISQR);
		cout<<histCorrelation<<"\n";
		if(histCorrelation > 75){
			alarm=1;	
			hconcat(image_old,image,image);
			cout<<"ALERT, DETECTED!!!\n";
			imshow("image", image);
      if(waitKey(10000) >= 0) break;
		}
	}
----

A função https://docs.opencv.org/2.4.13.7/doc/tutorials/imgproc/histograms/histogram_comparison/histogram_comparison.html[compareHist()], Própria do openCV realiza os cálculos de diferença entre os histogramas e possui três argumentos: Os dois histogramas a serem comparados e o método utilizado para tal. Os métodos aceitos para comparação são a Correlação, Distância Qui-quadrada, Interseção e Distância Bhattacharyya. No código desenvolvido utilizou-se  a Distância Qui-quadrada (CV_COMP_CHISQR), pois dentre os modelos disponíveis foi o que melhor se adequou a proposta.

.Equação da Distância Qui-quadrada
image::/image/dist.png[]

Um exemplo do funcionamento do programa link:/source_codes/motiondetector.cpp[motiondetector.cpp] pode ser visto no vídeo abaixo:

.Execução do programa _motiondetector.cpp_
video::_sl0xxIOKLU[youtube]

== Filtro espacial

A filtragem espacial no contexto de Processamento Digital de Sinais trata-se do processo de convolução digital da matriz que representa a imagem e de uma máscara que representa o efeito do filtro desejado.

=== Filtro Laplaciano do Gaussiano

O programa desenvolvido utiliza como base o código link:https://agostinhobritojr.github.io/tutorial/pdi/exemplos/filtroespacial.cpp[filtroespacial.cpp], disponibilizado pelo Prof. Agostinho em sua página do Github.

O programa base utiliza da convolução digital para realizar alguns processos de filtragem: Filtro da média, Gaussiana, Horizontal, Absoluto, Vertical e Laplaciano.

.Matrizes utilizadas para os filtros
[source,cpp]
----
float media[] = {1,1,1,
				   1,1,1,
				   1,1,1};
float gauss[] = {1,2,1,
				   2,4,2,
				   1,2,1};
float horizontal[]={-1,0,1,
					  -2,0,2,
					  -1,0,1};
float vertical[]={-1,-2,-1,
					0,0,0,
					1,2,1};
float laplacian[]={0,-1,0,
					 -1,4,-1,
					 0,-1,0};
----

Dentro do programa, após selecionar o tipo de filtro a ser aplicado, a matriz correspondete será transformada em uma máscara, que será utilizada no processo de filtagem ddo frame capturado pela câmera. O trecho de código abaixo demonstra o uso do construtor da classe link:https://docs.opencv.org/3.1.0/d3/d63/classcv_1_1Mat.html[_Mat()_] para definir a máscara.

.Criando a máscara do filtro
[source,cpp]
----
mask = Mat(3, 3, CV_32F, laplacian);
----

O algoritmo possui um laço de repetição que sempre captura o frame do dispositivo de imagem, no caso a webcam integrada, e aplica a máscara selecionada. A seleção do tipo de filtro é realizado no momento em que o usuário informa uma letra com mostra o esquema abaixo.

.Menu apresentando ao usuário para escolha do filtro
[source,cpp]
----
void menu(){
  cout << "\npressione a tecla para ativar o filtro: \n"
	"a - calcular modulo\n"
	"m - media\n"
	"g - gauss\n"
	"v - vertical\n"
	"h - horizontal\n"
	"l - laplaciano\n"
	"x - laplaciano gaussiano\n"
	"esc - sair\n";
}
----

.Trecho responsável pela filtragem ao escolher a opção 'l'
[source,cpp]
----
case 'l':
		menu();
		mask = Mat(3, 3, CV_32F, laplacian);
		printmask(mask);
		filter2D(frame32f, frameFiltered,
		frame32f.depth(), mask, Point(1,1), 0);
		if(absolut){
			frameFiltered=abs(frameFiltered);
		}
		frameFiltered.convertTo(result, CV_8U);
		break;
----

No código desenvolvido pelo autor, era necessário criar um novo filtro: Laplaciano do Gaussiano, que corresponde a aplicar primeiro o filtro Gaussiano e aplicar o filtro laplaciano no resultado.
No código base, o processo de filtragem utilizando a função link:https://docs.opencv.org/2.4.13.7/doc/tutorials/imgproc/imgtrans/filter_2d/filter_2d.html[_filter2D()_] ocorre dentro de cada *_case_*. Para realizar os filtros em cadeia, alterou-se o código de forma que o processo de filtragem ocorra sempre no início do _loop_ e cada condicional é responsável por definir a variável *_mask_* a ser usada no filtro. Com isso, os condicionais possuem formato semelhante ao trecho de código

.Criação da máscara ao selecionar a opção 'l'
[source,cpp]
----
case 'l':
		menu();
		lapgauss=0;
		mask = Mat(3, 3, CV_32F, laplacian);
		printmask(mask);
		break;
----

A variável _lapgauss_ funciona como uma flag para indicar se o filtro Laplaciano do Gaussiano está sendo utilizado. O valor 0 indica que não está em uso e o valor 1 indica o uso. Tal variável é necessária pois, como aplica-se filtros em cadeia a definição da máscara deste tipo de filtro está representado no código abaixo.

.Criação da mpascara ao selecionar a opção 'x'
[source,cpp]
----
case 'x':
		menu();
		lapgauss=1;
		mask = Mat(3, 3, CV_32F, gauss);
		scaleAdd(mask, 1/16.0, Mat::zeros(3,3,CV_32F), mask1);
		mask = mask1;
		filter2D(frame32f, frameFiltered,frame32f.depth(), mask, Point(1,1), 0);
		mask = Mat(3, 3, CV_32F, laplacian);
		filter2D(frameFiltered, frameFilteredLapGauss,frameFiltered.depth(), mask, Point(1,1), 0);
		break;
----

Os inicíos dos laços de repetição dos códigos link:https://agostinhobritojr.github.io/tutorial/pdi/exemplos/filtroespacial.cpp[base] e do link:/source_codes/lapgauss.cpp[lapgauss.cpp] podem ser vistos nos trechos abaixo.

.Inicio do loop no código _filtroespacial.cpp_
[source,cpp]
----
menu();
	for(;;){
		video >> cap; 
		cvtColor(cap, frame, CV_BGR2GRAY);
		flip(frame, frame, 1);
		imshow("original", frame);
		frame.convertTo(frame32f, CV_32F);
		imshow("filtroespacial", result);
		key = (char) waitKey(10);
		if( key == 27 ) break; // esc pressed!
		switch(key){
----

.Inicio do loop no código _lapgausse.cpp_
[source,cpp]
----
menu();
	for(;;){
		video >> cap; 
    cvtColor(cap, frame, CV_BGR2GRAY);
    flip(frame, frame, 1);
    imshow("original", frame);
		frame.convertTo(frame32f, CV_32F);
		if(lapgauss!=0){
			if(absolut){
      	frameFilteredLapGauss=abs(frameFilteredLapGauss);
    	}
    	frameFilteredLapGauss.convertTo(result, CV_8U);
			imshow("filtroespacial", result);
		}
		else{
    	filter2D(frame32f, frameFiltered,frame32f.depth(), mask, Point(1,1), 0);
    	if(absolut){
      	frameFiltered=abs(frameFiltered);
    	}
    	frameFiltered.convertTo(result, CV_8U);
			imshow("filtroespacial", result);
		}
    
    key = (char) waitKey(10);
    if( key == 27 ) break; // esc pressed!
    switch(key){
----

A execução do programa e comparação do resultados dos filtros pode ser vista nas imagens abaixo.

.Imagem original capturada
image::/image/filtrooriginal.png[]

.Aplicação do filtro Laplaciano
image::/image/filtrolap.png[]

.Aplicação do filtro Laplaciano do Gaussiano
image::/image/filtrolapgauss.png[]

== Projetos da Segunda Unidade

=== Filtro Homomórfico

O código pode ser encontrado em link:/source_codes/homomorfico.cpp[homomorfico.cpp]

O resultado pode ser observado na imagem abaixo, onde a da esquerda é a imagem utilizada na entrada (mal iluminada) e a sua direita a imagem após passar pelo filtro.

.Saida do filtro homomórfico
image::/image/homomorf.png[]

=== Detector de bordas de Canny

O código desenvolvido que possui a combinação do pontilhismo com o detector de bordas de Canny pode ser encontrado em link:/source_codes/cannypoints.cpp[cannypoints.cpp].

As imagens abaixo representam, respectivamente, a imagem utilizada na entrada do programa, as bordas detectadas, a imagem pontilhista e a saída do algoritmo

.Imagem de entrada
image::/image/mosaic.jpg[]

.Bordas detectadas com o alogritmo de Canny
image::/image/cannyborders.png[]

.Imagem pontilhista
image::/image/pontos.jpg[]

.Imagem de saida
image::/image/nova_arte.png[]

=== Kmeans

O código pode ser encontrado em link:/source_codes/kmeans_exe.cpp[kmeans_exe.cpp]

O resultado pode ser visto na imagem abaixo

.Saida do programa
image::/image/kmeans.gif[]
